{"cells":[{"cell_type":"markdown","id":"0b1f2fd1","metadata":{"id":"0b1f2fd1"},"source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/datafyresearcher/datafy-llm-workshop/blob/main/notebooks/04_LangChain_Agents.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"]},{"cell_type":"markdown","id":"52824b89-532a-4e54-87e9-1410813cd39e","metadata":{"id":"52824b89-532a-4e54-87e9-1410813cd39e"},"source":["# Chains in LangChain\n","\n","A LLM chain is the collection of steps in order to perform / follow instructions as per user input template. The chains enhances the cpability of LLMs and are the key building blocks of the generative-ai applicaions. As names suggested, the output of one component becomes the input of next component. Users can use the LLM model of their Choice. In this notebook we explore the OpenAI GPT-3.5.\n","\n","## Most Common LLM Chains\n","\n","* LLMChain\n","* Sequential Chains\n","  * SimpleSequentialChain\n","  * SequentialChain\n","* Conversational Retrieval QA (RAG Systems)\n","* Router Chain\n","\n","[1] https://medium.com/dev-genius/llm-chains-theoretical-overview-5f8fdad3f081"]},{"cell_type":"code","execution_count":3,"id":"slEWKJ9_U1yM","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13166,"status":"ok","timestamp":1718274283386,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"},"user_tz":-300},"id":"slEWKJ9_U1yM","outputId":"28b7adfe-40ad-43b3-9b93-e91f0ae6511b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on CoLab\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["if 'google.colab' in str(get_ipython()):\n","  print('Running on CoLab')\n","  # Install the package\n","  !pip install -q langchain==0.2.3 openai==1.34.0 litellm==1.40.9 langchain-community==0.2.4\n","else:\n","  print('Not running on CoLab')"]},{"cell_type":"code","execution_count":null,"id":"541eb2f1","metadata":{"id":"541eb2f1","tags":[]},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"gI--cAHsVfLa","metadata":{"id":"gI--cAHsVfLa"},"source":["#OpenAI API\n","\n","Let us try first using Openai API directly\n","\n","Read about the OpenAI API specifications and endpoints on below link\n","\n","https://platform.openai.com/docs/api-reference\n","\n","To learn about the available Models\n","\n","https://platform.openai.com/docs/models/gpt-3-5"]},{"cell_type":"code","execution_count":null,"id":"b7ed03ed-1322-49e3-b2a2-33e94fb592ef","metadata":{"id":"b7ed03ed-1322-49e3-b2a2-33e94fb592ef","tags":[]},"outputs":[],"source":["import os\n","import openai\n","\n","# select the model to use\n","llm_model = \"gpt-3.5-turbo-0613\"\n","\n","# openai.api_key = \"\"\n","\n","os.environ['OPENAI_API_KEY'] = \"\"\n","\n","# os.environ[\"OPENAI_API_KEY\"] = \"sk-litellm-7_NPZhMGxY2GoHC59LgbDw\" # [OPTIONAL] replace with your openai key"]},{"cell_type":"markdown","id":"9f3b61a3-92eb-4891-90ee-1d10607b05ad","metadata":{"id":"9f3b61a3-92eb-4891-90ee-1d10607b05ad"},"source":["Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."]},{"cell_type":"code","execution_count":null,"id":"b84e441b","metadata":{"id":"b84e441b","tags":[]},"outputs":[],"source":["#!pip install pandas"]},{"cell_type":"code","execution_count":null,"id":"974acf8e-8f88-42de-88f8-40a82cb58e8b","metadata":{"id":"974acf8e-8f88-42de-88f8-40a82cb58e8b","tags":[]},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv('https://raw.githubusercontent.com/amjadraza/dlai-langchain/main/notebooks/langchain/Data.csv')"]},{"cell_type":"code","execution_count":null,"id":"b7a09c35","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1695942736023,"user":{"displayName":"Muhammad Raza","userId":"10265348660845665358"},"user_tz":-600},"id":"b7a09c35","outputId":"9ec98b3f-512f-4c10-9b15-191a9c5cf45c","tags":[]},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-3f271ac1-3ddc-4c90-90bc-f96b74cedc71\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Product</th>\n","      <th>Review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Queen Size Sheet Set</td>\n","      <td>I ordered a king size set. My only criticism w...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Waterproof Phone Pouch</td>\n","      <td>I loved the waterproof sac, although the openi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Luxury Air Mattress</td>\n","      <td>This mattress had a small hole in the top of i...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Pillows Insert</td>\n","      <td>This is the best throw pillow fillers on Amazo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Milk Frother Handheld\\n</td>\n","      <td>I loved this product. But they only seem to l...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f271ac1-3ddc-4c90-90bc-f96b74cedc71')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3f271ac1-3ddc-4c90-90bc-f96b74cedc71 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3f271ac1-3ddc-4c90-90bc-f96b74cedc71');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-df342b8e-b268-40c1-a5f3-79d234cb7a1b\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df342b8e-b268-40c1-a5f3-79d234cb7a1b')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-df342b8e-b268-40c1-a5f3-79d234cb7a1b button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                   Product                                             Review\n","0     Queen Size Sheet Set  I ordered a king size set. My only criticism w...\n","1   Waterproof Phone Pouch  I loved the waterproof sac, although the openi...\n","2      Luxury Air Mattress  This mattress had a small hole in the top of i...\n","3           Pillows Insert  This is the best throw pillow fillers on Amazo...\n","4  Milk Frother Handheld\\n   I loved this product. But they only seem to l..."]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"markdown","id":"b940ce7c","metadata":{"id":"b940ce7c"},"source":["## LLMChain\n","\n","Let us explore the very simple Chain implemented in LangChain Python Package."]},{"cell_type":"code","execution_count":4,"id":"e92dff22","metadata":{"id":"e92dff22","tags":[],"executionInfo":{"status":"ok","timestamp":1718274289273,"user_tz":-300,"elapsed":1971,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"}}},"outputs":[],"source":["from langchain.chat_models import ChatOpenAI, ChatLiteLLM\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.chains import LLMChain"]},{"cell_type":"code","execution_count":null,"id":"943237a7","metadata":{"id":"943237a7","tags":[]},"outputs":[],"source":["# Instantiate the LLM\n","llm = ChatOpenAI(temperature=0.9, model=llm_model)\n","\n","# Instantiate the liteLLM Model\n","\n","llm_lite = ChatLiteLLM(model=\"gpt-3.5-turbo\", temperature = 0.9)"]},{"cell_type":"code","execution_count":null,"id":"cdcdb42d","metadata":{"id":"cdcdb42d","tags":[]},"outputs":[],"source":["prompt = ChatPromptTemplate.from_template(\n","    \"What is the best tagline to describe \\\n","    a company that makes or produces or supply {product}?\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"d7abc20b","metadata":{"id":"d7abc20b","tags":[]},"outputs":[],"source":["chain = LLMChain(llm=llm_lite, prompt=prompt)"]},{"cell_type":"code","execution_count":null,"id":"ad44d1fb","metadata":{"id":"ad44d1fb","tags":[]},"outputs":[],"source":["product = \"Generative AI\"\n","response = chain.run(product)"]},{"cell_type":"code","execution_count":null,"id":"lo9qdBEaWzjR","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1695943100979,"user":{"displayName":"Muhammad Raza","userId":"10265348660845665358"},"user_tz":-600},"id":"lo9qdBEaWzjR","outputId":"884a5068-2e46-4ee4-f5ba-4cd2f304f406"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\"Unleashing the Potential of Generative AI\"'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["response"]},{"cell_type":"markdown","id":"69b03469","metadata":{"id":"69b03469"},"source":["## SimpleSequentialChain\n","\n","SImpleSequentialChain is another widely used LLMChain implemented in LangChain and serve as the key building block of AGIs.\n","\n","The SimpleSequentialChain is a type of sequential chain in the Langchain library. It allows you to connect multiple chains and compose them into pipelines that execute a specific scenario. Each step in the chain has a singular input and output, where the output of one step is the input to the next."]},{"cell_type":"code","execution_count":5,"id":"febee243","metadata":{"id":"febee243","tags":[],"executionInfo":{"status":"ok","timestamp":1718274293710,"user_tz":-300,"elapsed":6,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"}}},"outputs":[],"source":["from langchain.chains import SimpleSequentialChain"]},{"cell_type":"code","execution_count":null,"id":"2f31aa8a","metadata":{"id":"2f31aa8a","tags":[]},"outputs":[],"source":["llm = ChatOpenAI(temperature=0.7, model=llm_model)\n","\n","# prompt template 1\n","first_prompt = ChatPromptTemplate.from_template(\n","    \"What is the best tagline to describe \\\n","    a company that makes or produces or supply {product}?\"\n",")\n","\n","# Chain 1\n","chain_one = LLMChain(llm=llm, prompt=first_prompt)"]},{"cell_type":"code","execution_count":null,"id":"3f5d5b76","metadata":{"id":"3f5d5b76","tags":[]},"outputs":[],"source":["# prompt template 2\n","second_prompt = ChatPromptTemplate.from_template(\n","    \"Write a Business Proposal note more than 20 lines using \\\n","   tagline :{tagline}\"\n",")\n","# chain 2\n","chain_two = LLMChain(llm=llm, prompt=second_prompt)"]},{"cell_type":"code","execution_count":null,"id":"6c1eb2c4","metadata":{"id":"6c1eb2c4","tags":[]},"outputs":[],"source":["overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n","                                             verbose=True\n","                                            )"]},{"cell_type":"code","execution_count":null,"id":"78458efe","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21402,"status":"ok","timestamp":1695943131380,"user":{"displayName":"Muhammad Raza","userId":"10265348660845665358"},"user_tz":-600},"id":"78458efe","outputId":"e0f0caca-bbc3-4032-cb87-e22783a80cfc","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n","\u001b[36;1m\u001b[1;3m\"Unleashing the Power of Generative AI for Limitless Possibilities\"\u001b[0m\n","\u001b[33;1m\u001b[1;3mDear [Client's Name],\n","\n","I hope this note finds you well. I am writing to present you with an exciting opportunity to harness the power of generative AI and unlock limitless possibilities for your business. Our tagline, \"Unleashing the Power of Generative AI for Limitless Possibilities,\" perfectly encapsulates the potential that this technology holds for your organization.\n","\n","At [Your Company Name], we specialize in developing cutting-edge AI solutions that drive innovation and help businesses thrive in the digital era. Generative AI, in particular, has emerged as a groundbreaking technology that can revolutionize various aspects of your operations, from product design to customer engagement.\n","\n","By leveraging the power of generative AI, we can assist you in creating highly realistic and customizable virtual prototypes of your products. This will not only accelerate your product development process but also enable you to visualize and iterate on designs more efficiently than ever before. The possibilities are truly limitless when it comes to exploring new concepts and pushing the boundaries of creativity.\n","\n","Furthermore, generative AI can be a game-changer in enhancing customer experiences. By analyzing vast amounts of data, our AI algorithms can generate personalized recommendations, tailored advertisements, and interactive interfaces that resonate with your target audience. This level of customization can significantly improve customer engagement, leading to increased sales and brand loyalty.\n","\n","In addition to product design and customer engagement, generative AI can also optimize your business operations. Our AI models can analyze complex datasets and identify patterns, enabling you to make data-driven decisions that drive efficiency and cost-effectiveness. From supply chain management to predictive maintenance, this technology can streamline your operations and provide a competitive edge in today's fast-paced business landscape.\n","\n","To ensure the success of our collaboration, we propose a phased approach. First, we will conduct a thorough analysis of your business requirements and identify the areas where generative AI can have the greatest impact. Based on these findings, our team of AI experts will develop tailored solutions that align with your objectives and budget. Throughout the implementation process, we will provide comprehensive training and support to your staff, ensuring a seamless transition to the new AI-powered workflows.\n","\n","We firmly believe that by embracing the power of generative AI, your business can not only stay ahead of the competition but also pioneer new trends and disrupt industries. The possibilities are truly limitless, and we are excited to embark on this transformative journey with you.\n","\n","If you are interested in exploring this opportunity further or have any questions, please do not hesitate to reach out. We would be delighted to schedule a meeting to discuss the potential benefits that generative AI can offer your organization.\n","\n","Thank you for considering our proposal. We look forward to the possibility of working together and unleashing the power of generative AI for your business.\n","\n","Sincerely,\n","\n","[Your Name]\n","[Your Company Name]\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}],"source":["response = overall_simple_chain.run(product)"]},{"cell_type":"markdown","id":"7b5ce18c","metadata":{"id":"7b5ce18c"},"source":["## SequentialChain\n","\n","In a SimpleSequentialChain, each step has a singular input and output, where the output of one step is the input to the next. This is useful when you want to take the output from one call and use it as the input to another.\n","\n","In a SequentialChain, you can have multiple inputs and outputs. This is useful for more complex scenarios where you need to pass multiple variables between chains."]},{"cell_type":"code","execution_count":6,"id":"4c129ef6","metadata":{"id":"4c129ef6","tags":[],"executionInfo":{"status":"ok","timestamp":1718274298646,"user_tz":-300,"elapsed":4,"user":{"displayName":"Datafy Research","userId":"04455658766472393665"}}},"outputs":[],"source":["from langchain.chains import SequentialChain"]},{"cell_type":"code","execution_count":null,"id":"016187ac","metadata":{"id":"016187ac","tags":[]},"outputs":[],"source":["llm = ChatOpenAI(temperature=0.9, model=llm_model)\n","\n","# prompt template 1: translate to english\n","first_prompt = ChatPromptTemplate.from_template(\n","    \"Translate the following review to english:\"\n","    \"\\n\\n{Review}\"\n",")\n","# chain 1: input= Review and output= English_Review\n","chain_one = LLMChain(llm=llm, prompt=first_prompt,\n","                     output_key=\"English_Review\"\n","                    )\n"]},{"cell_type":"code","execution_count":null,"id":"0fb0730e","metadata":{"id":"0fb0730e","tags":[]},"outputs":[],"source":["second_prompt = ChatPromptTemplate.from_template(\n","    \"Can you summarize the following review in 1 sentence:\"\n","    \"\\n\\n{English_Review}\"\n",")\n","# chain 2: input= English_Review and output= summary\n","chain_two = LLMChain(llm=llm, prompt=second_prompt,\n","                     output_key=\"summary\"\n","                    )\n"]},{"cell_type":"code","execution_count":null,"id":"6accf92d","metadata":{"id":"6accf92d","tags":[]},"outputs":[],"source":["# prompt template 3: translate to english\n","third_prompt = ChatPromptTemplate.from_template(\n","    \"What language is the following review:\\n\\n{Review}\"\n",")\n","# chain 3: input= Review and output= language\n","chain_three = LLMChain(llm=llm, prompt=third_prompt,\n","                       output_key=\"language\"\n","                      )\n"]},{"cell_type":"code","execution_count":null,"id":"c7a46121","metadata":{"id":"c7a46121","tags":[]},"outputs":[],"source":["\n","# prompt template 4: follow up message\n","fourth_prompt = ChatPromptTemplate.from_template(\n","    \"Write a follow up response to the following \"\n","    \"summary in the specified language:\"\n","    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",")\n","# chain 4: input= summary, language and output= followup_message\n","chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n","                      output_key=\"followup_message\"\n","                     )\n"]},{"cell_type":"code","execution_count":null,"id":"89603117","metadata":{"id":"89603117","tags":[]},"outputs":[],"source":["# overall_chain: input= Review\n","# and output= English_Review,summary, followup_message\n","overall_chain = SequentialChain(\n","    chains=[chain_one, chain_two, chain_three, chain_four],\n","    input_variables=[\"Review\"],\n","    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n","    verbose=True\n",")"]},{"cell_type":"code","execution_count":null,"id":"51b04f45","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16493,"status":"ok","timestamp":1695943473175,"user":{"displayName":"Muhammad Raza","userId":"10265348660845665358"},"user_tz":-600},"id":"51b04f45","outputId":"849b1931-d01d-46b1-8a7c-14f451a5af95","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"data":{"text/plain":["{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n"," 'English_Review': \"I find the taste mediocre. The foam doesn't hold, it's weird. I buy the same ones in stores, and the taste is much better...\\nOld batch or counterfeit!?\",\n"," 'summary': \"The reviewer finds the taste of the product mediocre, and suspects that it might be an old batch or counterfeit since the foam doesn't hold and the taste is better when bought from stores.\",\n"," 'followup_message': \"Réponse de suivi:\\n\\nCher(e) critique,\\n\\nNous vous remercions d'avoir pris le temps de partager vos commentaires sur notre produit. Nous sommes désolés d'apprendre que la saveur ne vous a pas entièrement satisfait(e). Nous souhaitons souligner que notre produit est fabriqué avec des ingrédients de haute qualité et selon des normes rigoureuses de production. \\n\\nIl est possible que vous ayez reçu un lot plus ancien ou éventuellement une contrefaçon. Nous prenons cette question très au sérieux et nous aimerions en apprendre davantage. Pourriez-vous s'il vous plaît nous donner plus de détails sur la date et le lieu d'achat ? Cela nous aiderait à enquêter sur ce problème.\\n\\nNous tenons à vous assurer que nous faisons tout notre possible pour maintenir la qualité de nos produits et que la satisfaction de nos clients est notre priorité absolue. Nous avons également transmis vos commentaires à notre équipe de production pour qu'ils puissent enquêter de leur côté.\\n\\nDans l'attente de votre réponse et en vous remerciant encore une fois pour votre avis, nous espérons pouvoir continuer à vous fournir des produits de qualité.\\n\\nBien à vous,\\n\\nL'équipe du service client\"}"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["review = df.Review[5]\n","overall_chain(review)"]},{"cell_type":"code","execution_count":null,"id":"912633a1","metadata":{"id":"912633a1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"d6378a95","metadata":{"id":"d6378a95"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0cd9456d","metadata":{"id":"0cd9456d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"77c46ddf","metadata":{"id":"77c46ddf"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}